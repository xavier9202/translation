{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper LoRA Training on Google Colab\n",
    "\n",
    "This notebook prepares a Colab GPU runtime, installs dependencies, and launches the same `scripts/train.py` command you were running locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU availability\n",
    "Make sure Colab actually gave us a CUDA device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-check"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pull the project into the Colab VM\n",
    "\n",
    "Set `REPO_URL` to your fork (or the upstream repo if it contains the latest changes you need). If your project isn’t on GitHub, upload a ZIP via the *Files* pane and replace this cell with the appropriate unzip commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/<your-username>/ChineseTaiwaneseWhisper.git\"  # <-- edit me\n",
    "BRANCH = \"main\"\n",
    "PROJECT_DIR = \"/content/ChineseTaiwaneseWhisper\"\n",
    "\n",
    "if REPO_URL.startswith(\"https://github.com/\"):\n",
    "    if not os.path.exists(PROJECT_DIR):\n",
    "        !git clone --depth 1 -b $BRANCH $REPO_URL $PROJECT_DIR\n",
    "    else:\n",
    "        print(f\"Skipping clone; {PROJECT_DIR} already exists\")\n",
    "else:\n",
    "    raise ValueError(\"Please set REPO_URL to your repository URL (https://github.com/...) or upload a ZIP instead.\")\n",
    "\n",
    "%cd $PROJECT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (Optional) Mount Google Drive for persistent checkpoints\n",
    "Skip this if you’re fine with storing outputs in the ephemeral Colab filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "MOUNT_DRIVE = False  # Set to True if you want to store outputs on Google Drive\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/whisper-medium-taiwanese-lora\"\n",
    "\n",
    "if MOUNT_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "    print(f\"Drive mounted. Outputs will be stored under {DRIVE_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Install dependencies (GPU wheels for PyTorch + project requirements)\n",
    "This installs a CUDA-enabled PyTorch build alongside the packages listed in `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install torch==2.5.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure and launch training\n",
    "Adjust any of the parameters below before running. The defaults mirror your local command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define-training-command"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"openai/whisper-medium\"\n",
    "LANGUAGE = \"chinese\"\n",
    "OUTPUT_DIR = DRIVE_OUTPUT_DIR if 'DRIVE_OUTPUT_DIR' in globals() and MOUNT_DRIVE else \"./whisper-medium-taiwanese-lora\"\n",
    "PREPROCESS_WORKERS = 4\n",
    "TRAIN_CMD = f\"\"\"\n",
    "python scripts/train.py \\\n",
    "  --model_name_or_path \\\"{MODEL_NAME}\\\" \\\n",
    "  --language \\\"{LANGUAGE}\\\" \\\n",
    "  --use_peft \\\n",
    "  --peft_method \\\"lora\\\" \\\n",
    "  --dataset \\\"common_voice_13_train\\\" \\\n",
    "  --dataset_dir \\\".\\\" \\\n",
    "  --output_dir \\\"{OUTPUT_DIR}\\\" \\\n",
    "  --num_train_epochs 10 \\\n",
    "  --per_device_train_batch_size 4 \\\n",
    "  --gradient_accumulation_steps 4 \\\n",
    "  --learning_rate 1e-5 \\\n",
    "  --fp16 \\\n",
    "  --timestamp False \\\n",
    "  --logging_steps 50 \\\n",
    "  --save_steps 500 \\\n",
    "  --preprocessing_num_workers {PREPROCESS_WORKERS}\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Training command:\\n\", TRAIN_CMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-training"
   },
  "outputs": [],
  "source": [
    "# Launch training (this will stream logs and the tqdm progress bar)\n",
    "import os\n",
    "\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "os.environ.setdefault(\"USE_MLFLOW\", \"false\")  # keep MLflow optional unless you configure it explicitly\n",
    "\n",
    "!{TRAIN_CMD}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
